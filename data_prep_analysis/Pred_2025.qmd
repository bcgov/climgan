---
title: "2025 GAN Runs"
author: "Tirion"
format: html
editor: visual
---

```{python}
import torch
import numpy as np
import mlflow
import xarray as xr
from matplotlib import pyplot as plt
from matplotlib import colorbar, colors, gridspec
import pandas as pd
```

## Load training data:

```{r}
library(data.table)
library(terra)
```

```{r}
prism_folder <- "C:/Users/TGRICE/OneDrive - Government of BC/Documents/GANs/PRISM/prec/sep/"

era5_folder <- "C:/Users/TGRICE/OneDrive - Government of BC/Documents/GANs/era5_clim/prec/"

dem_folder <- "C:/Users/TGRICE/OneDrive - Government of BC/Documents/GANs/dem/"

dem <- rast(paste(dem_folder, "dem_NWNA_coarse.nc", sep = ""))

# extend dem 1 degree south and add band of zeroes
# extended <- ext(ext(dem)[1], ext(dem)[2], ext(dem)[3] - 1, ext(dem)[4])
# dem_extended <- rast(extended, resolution = res(dem), crs = crs(dem))
# values(dem_extended) <- 0
# dem_extended <- merge(dem, dem_extended)
# writeCDF(dem_extended, paste0(dem_folder, "dem_pred.nc"), overwrite = TRUE)


plot(dem)
# plot(dem_extended)

# land_mask <- dem > 0  
# plot(land_mask)

era5 <- rast(paste(era5_folder, "ppt_1981_2010_cropped.nc", sep = ""))

plot(era5[[9]]) # by month

prism <- rast(paste(prism_folder, "prism_train_coarse.nc", sep=""))

# months <- c("jan", "feb", "mar", "apr", "may", "jun",
#             "jul", "aug", "sep", "oct", "nov", "dec")
# 
# prism_list <- lapply(months, function(m) {
#   rast(file.path(prism_folder, m, "prism_train_coarse.nc"))
# })
# names(prism_list) <- paste0("prism_", months)

dim(era5)
dim(prism)
dim(dem)
plot(prism)

#sbeale <- rast("O:/Mosaic_Yukon/operational/WorldClim/prec/feb/Predictions/GAN_gen150.nc")

# writeCDF(land_mask, paste0(dem_folder, "dem_mask.nc"), varname='tmax', overwrite = T)

# extend PRISM coast
extend.coastal <- function(x){
  x <- focal(x, w=3, fun="mean", na.policy="only") 
  x <- focal(x, w=5, fun="mean", na.policy="only") 
  x <- focal(x, w=7, fun="mean", na.policy="only") 
  x <- focal(x, w=9, fun="mean", na.policy="only") 
  values(x)[!is.finite(values(x))] <- NA
  return(x)
}

prism_extended <- extend.coastal(prism)
writeCDF(prism_extended, paste0(prism_folder, "prism_train_coarse_ext.nc"), varname='tmax', overwrite = T)

prism_test <- rast(paste(prism_folder, "prism_test.nc", sep=""))
prism_test_extended <- extend.coastal(prism_test)
writeCDF(prism_test_extended, paste0(prism_folder, "prism_test_ext.nc"), varname='tmax', overwrite = T)
```

```{python}

# load in folders  
era5_folder = r.era5_folder
prism_folder = r.prism_folder
dem_folder = r.dem_folder

## ERA5
era5_fields = xr.open_dataset(era5_folder + "ppt_1981_2010_cropped.nc")
era5 = torch.from_numpy(era5_fields.to_array().to_numpy())[0,...]
era5_stand_fields = xr.open_dataset(era5_folder + "ppt_full.nc")
era5_stand = torch.from_numpy(era5_stand_fields.to_array().to_numpy())[0,...]

# standardize
mask = ~torch.isnan(era5_stand)
era5_mean = era5_stand[mask].mean()
era5_std = era5_stand[mask].std()
standardized_era5 = (era5 - era5_mean) / era5_std

plt.close()
plt.imshow(standardized_era5[8]) # by month
plt.show()

## PRISM
# months = ["jan", "feb", "mar", "apr", "may", "jun",
#           "jul", "aug", "sep", "oct", "nov", "dec"]
# prism_list = []
# 
# for m in months:
#   prism_fields = xr.open_dataset(prism_folder + m +"/prism_train_coarse.nc")
#   prism = torch.from_numpy(prism_fields.to_array().to_numpy())[0,...]
#   prism_list.append(prism)
  
prism_fields = xr.open_dataset(prism_folder + "prism_train_coarse_ext.nc")
prism = torch.from_numpy(prism_fields.to_array().to_numpy())[0,...]

# standardize - PRISM already standardized

plt.close()
plt.imshow(prism)
plt.show()

## DEM
dem_fields = xr.open_dataset(dem_folder + "dem_NWNA_coarse.nc")
dem = torch.from_numpy(dem_fields.to_array().to_numpy())[0,...]
dem_stand_fields = xr.open_dataset(dem_folder + "dem_full.nc")
dem_stand = torch.from_numpy(dem_stand_fields.to_array().to_numpy())[0,...]

# standardize
mask = ~torch.isnan(dem_stand)
dem_mean = dem_stand[mask].mean()
dem_std = dem_stand[mask].std()
standardized_dem = (dem - dem_mean) / dem_std

plt.close()
plt.imshow(standardized_dem)
plt.show()
```

## Load test data:

```{python}

## ERA5
era5_test_fields = xr.open_dataset(era5_folder + "ppt_test.nc")
era5_test = torch.from_numpy(era5_test_fields.to_array().to_numpy())[0,...]

# standardize
standardized_era5_test = (era5_test - era5_mean) / era5_std

plt.close()
plt.imshow(standardized_era5_test[8]) # by month
plt.show()

## PRISM
# months = ["jan", "feb", "mar", "apr", "may", "jun",
#           "jul", "aug", "sep", "oct", "nov", "dec"]
# prism_list = []
# 
# for m in months:
#   prism_fields = xr.open_dataset(prism_folder + m +"/prism_train_coarse.nc")
#   prism = torch.from_numpy(prism_fields.to_array().to_numpy())[0,...]
#   prism_list.append(prism)
  
prism_test_fields = xr.open_dataset(prism_folder + "prism_test_ext.nc")
prism_test = torch.from_numpy(prism_test_fields.to_array().to_numpy())[0,...]
stand = pd.read_csv(prism_folder + "standardization.csv")

# standardize
prism_mean = stand["mean"][0]
prism_std = stand["std"][0]
standardized_prism_test = (prism_test - prism_mean) / prism_std

plt.close()
plt.imshow(standardized_prism_test)
plt.show()

## DEM
dem_test_fields = xr.open_dataset(dem_folder + "dem_test.nc")
dem_test = torch.from_numpy(dem_test_fields.to_array().to_numpy())[0,...]

# standardize
standardized_dem_test = (dem_test - dem_mean) / dem_std

plt.close()
plt.imshow(standardized_dem_test)
plt.show()
```

## Make tiles:

```{python}
import math

def tile_data(tensor, tile_size, offset):
  h, w = tensor.size(1), tensor.size(2)
  res_ls = []
  for y in range(int(math.ceil(h/offset))):
    for x in range(int(math.ceil(w/offset))):
      curr = tensor[:, offset*y:min(offset*y+tile_size, h), offset*x:min(offset*x+tile_size, w)]
      if(y == 0):
        res_ls.append([curr])
      else:
        res_ls[x].append(curr)
  res_pad = [[torch.nn.functional.pad(ten, (0,tile_size-ten.shape[2],0,tile_size - ten.shape[1],0,0), mode = "constant", value = 0) for ten in x] for x in res_ls]
  return(res_pad)

def remove_tiles(prism, era5, dem):
  assert prism.size(0) == era5.size(0) == dem.size(0), "Tensors must be same size"
  prism_nan = torch.isnan(prism).view(prism.size(0), -1).any(dim=1)
  era5_nan  = torch.isnan(era5).view(era5.size(0), -1).any(dim=1)
  dem_nan   = torch.isnan(dem).view(dem.size(0), -1).any(dim=1)
  bad_tiles = prism_nan | era5_nan | dem_nan
  clean_prism = prism[~bad_tiles]
  clean_era5 = era5[~bad_tiles]
  clean_dem = dem[~bad_tiles]
  return clean_prism, clean_era5, clean_dem

def remove_zero_tiles(prism, era5, dem):
  assert prism.size(0) == era5.size(0) == dem.size(0), "Tensors must be same size"
  zero_mask = (prism == 0).view(prism.size(0), -1).any(dim=1)
  clean_prism = prism[~zero_mask]
  clean_era5 = era5[~zero_mask]
  clean_dem = dem[~zero_mask]
  return clean_prism, clean_era5, clean_dem


def trim_tiles(tiles, batch_size):
  num_tiles = tiles.shape[0]
  remainder = num_tiles % batch_size
  
  if remainder != 0:
      tiles = tiles[:-remainder]
  
  return tiles

scale_factor = 12
tile_size = 96
offset = 12

## PRISM
# prism_list_tiles = [tile_data(prism.unsqueeze(0), tile_size, offset) for prism in prism_list]
# prism_test_tiles = tile_data(prism_list[0].unsqueeze(0), tile_size, offset)
prism_tiles = tile_data(prism.unsqueeze(0), tile_size, offset)
prism_test_tiles = tile_data(standardized_prism_test.unsqueeze(0), tile_size, offset)

## ERA5
# seqs = []
# for i in range(12):
#     seq = [i] + [x for x in range(12) if x != i]
#     seqs.append(seq)
#     
# era5_list_tiles = [tile_data(standardized_era5[seq,...], int(tile_size / scale_factor), int(offset / scale_factor)) for seq in seqs]
# era5_test_tiles = tile_data(standardized_era5[[0],...], int(tile_size / scale_factor), int(offset / scale_factor))
era5_tiles = tile_data(standardized_era5[[8,0,1,2,3,4,5,6,7,9,10,11],...], int(tile_size / scale_factor), int(offset / scale_factor))
era5_test_tiles = tile_data(standardized_era5_test[[8,0,1,2,3,4,5,6,7,9,10,11],...], int(tile_size / scale_factor), int(offset / scale_factor))

## DEM
dem_tiles = tile_data(standardized_dem.unsqueeze(0), tile_size, offset)
dem_test_tiles = tile_data(standardized_dem_test.unsqueeze(0), tile_size, offset)

plt.close()
plt.imshow(prism_tiles[4][8][0,...])
plt.show()
  
for num in range(12):
  plt.close()
  plt.imshow(era5_tiles[4][8][num,...])
  plt.show()

plt.close()
plt.imshow(dem_tiles[4][8][0,...])
plt.show()

plt.close()
plt.imshow(prism_test_tiles[2][4][0,...])
plt.show()

for num in range(12):
  plt.close()
  plt.imshow(era5_test_tiles[2][4][num,...])
  plt.show()

plt.close()
plt.imshow(dem_test_tiles[2][4][0,...])
plt.show()

#prism_tiles_flat = torch.cat([tile for month in prism_list_tiles for row in month for tile in row], dim=0)
prism_tiles_flat = torch.cat([tile for row in prism_tiles for tile in row], dim=0)
# need to use stack here instead of cat because there's 3 channels
era5_tiles_flat = torch.stack([tile for row in era5_tiles for tile in row], dim=0)
#era5_tiles_flat = torch.cat([tile.unsqueeze(0) for seq in era5_list_tiles for row in seq for tile in row], dim=0)
dem_tiles_flat = torch.cat([tile for row in dem_tiles for tile in row], dim=0)
#dem_tiles_flat = torch.cat([tile for row in dem_tiles for tile in row for _ in range(12)], dim=0)

prism_tiles_flat_test = torch.cat([tile for row in prism_test_tiles for tile in row], dim=0)
# need to use stack here instead of cat because there's 3 channels
era5_tiles_flat_test = torch.stack([tile for row in era5_test_tiles for tile in row], dim=0)
dem_tiles_flat_test = torch.cat([tile for row in dem_test_tiles for tile in row], dim=0)

# remove any tiles with missing values for training
clean_prism, clean_era5, clean_dem = remove_tiles(prism_tiles_flat, era5_tiles_flat, dem_tiles_flat)

# make sure number of tiles is a multiple of batch size = 10
clean_prism = trim_tiles(clean_prism, 20)
clean_era5 = trim_tiles(clean_era5, 20)
clean_dem = trim_tiles(clean_dem, 20)

# remove any tiles with missing values for testing
clean_prism_test, clean_era5_test, clean_dem_test = remove_tiles(prism_tiles_flat_test, era5_tiles_flat_test, dem_tiles_flat_test)

# remove any tiles that have any values=0 for testing
clean_prism_test, clean_era5_test, clean_dem_test = remove_zero_tiles(clean_prism_test, clean_era5_test, clean_dem_test)

# check shapes
print(clean_prism.shape)
print(clean_era5.shape)
print(clean_dem.shape)
print(clean_prism_test.shape)
print(clean_era5_test.shape)
print(clean_dem_test.shape)

torch.save(clean_prism, prism_folder + "prism_tiles.pt")
torch.save(clean_era5, era5_folder + "era5_tiles.pt")
torch.save(clean_dem, dem_folder + "dem_tiles.pt")

torch.save(clean_prism_test, prism_folder + "prism_test_tiles.pt")
torch.save(clean_era5_test, era5_folder + "era5_test_tiles.pt")
torch.save(clean_dem_test, dem_folder + "dem_test_tiles.pt")
```

## Load model & predict (done on thufir):

```{python}
G = torch.jit.load("C:/Users/TGRICE/OneDrive - Government of BC/Desktop/Generator_250.pt", map_location=torch.device('cpu'))
device = "cpu"

era5_tiles_gen = [[ten.unsqueeze(0) for ten in x] for x in era5_tiles]
dem_tiles_gen = [[ten.unsqueeze(0) for ten in x] for x in dem_tiles]

preds = [[G(era5.to(device).float(),dem.to(device).float()).cpu().detach() for era5, dem in zip(e1,d1)] for e1,d1 in zip(era5_tiles_gen, dem_tiles_gen)]
```

## Blending (done on thufir):

```{python}
from torch.nn import functional as nnf

ncol = len(preds)
nrow = len(preds[0])
scale_factor = 12
tile_size = 144
offset = 108
pad_size = int((tile_size-offset)/4)
overlap_size = pad_size * 2
new_size = tile_size - overlap_size
pad_size = int((tile_size-offset)/4)
overlap_size = pad_size * 2
new_size = tile_size - overlap_size

# crop edges
pred_crop = [[ten[0,0,pad_size:-pad_size,pad_size:-pad_size] for j,ten in enumerate(x)] for i,x in enumerate(preds)]

# make masks
t1 = torch.linspace(0,1,overlap_size).repeat(126,1)
t2 = torch.ones((126,126-(overlap_size*2))) 
t3 = torch.linspace(1,0,overlap_size).repeat(126,1)
tile_mask = torch.cat([t1,t2,t3], dim = 1).transpose(0,1)

def blend_row(row_ls):
  temp = torch.cat([x.reshape(1,new_size**2,1) for x in row_ls],dim = 2)
  out = nnf.fold(temp, (nrow*offset + overlap_size*2,new_size), kernel_size=(new_size,new_size), stride=offset).squeeze()
  return out

## mask individual tiles
mask_tiles = [[ten * tile_mask for ten in x] for x in pred_crop]
pred_cols = [blend_row(x) for x in mask_tiles]

## make column mask
col_dims = pred_cols[0].shape
t1 = torch.linspace(0,1,overlap_size).repeat(col_dims[0],1)
t2 = torch.ones((col_dims[0],126-(overlap_size*2))) 
t3 = torch.linspace(1,0,overlap_size).repeat(col_dims[0],1)
column_mask = torch.cat([t1,t2,t3], dim = 1)

mask_cols = [column_mask * x for x in pred_cols]

##blend and concatenate cols
temp = [x.reshape(1,col_dims[0]*col_dims[1],1) for x in mask_cols]
uf = torch.cat(temp, dim = 2)
raw = nnf.fold(uf, (col_dims[0],ncol*offset + overlap_size*2), kernel_size=col_dims, stride=offset)
result = raw.squeeze()

plt.close()
plt.imshow(result)
plt.show()

final_pad = nnf.pad(result, (pad_size,pad_size,pad_size,pad_size), mode = "constant", value = 0)

plt.close()
plt.imshow(final_pad)
plt.show()

torch.save(final_pad, "/sapho/tirion/GANs/results/" + "full_train_generator_250_results.pt")
```

## Create raster:

```{python}
final_pad = torch.load("O:/Mosaic_Yukon/Tirion/Results/foundational_model/tmax/Model2/jan/jan_gen250_fullregion.pt")

res_np = np.array(final_pad)

plt.close()
plt.imshow(res_np)
plt.show()

res_np.shape

dem = torch.load("O:/Mosaic_Yukon/Tirion/Results/foundational_model/tmax/Model2/jan/dem.pt")

dem_np = np.array(dem)

plt.close()
plt.imshow(dem_np)
plt.show()

res_np.shape
```

```{r}
library(terra)
library(data.table)
library(reticulate)
library(RColorBrewer)
library(raster)

results_folder <- "O:/Mosaic_Yukon/Tirion/Results/foundational_model/tmax/Model2/jan/"

data_folder <- "C:/Users/TGRICE/OneDrive - Government of BC/Documents/GANs/PRISM/tmax/jan/"

# dem <- rast(paste(dem_folder, "dem_test_cropped.nc", sep = ""))

# res <- dem_extended[[1]]
res <- py$dem_np
rast_dim <- dim(res)
preds <- py$res_np
dim(preds)

preds <- preds[1:rast_dim[1],1:rast_dim[2]]
values(res) <- preds
plot(res)

x <- read.csv(paste(data_folder, "standardization.csv", sep=""))

unstand_mean <- x[[3]][1]
unstand_std <- x[[4]][1]

res_us <- (res * unstand_std) + (unstand_mean)
plot(res_us)

# final <- mask(res_us, land_mask, maskvalues=FALSE)
# plot(final)

writeCDF(res_us, paste0(results_folder, "jan_fullregion.nc"), varname='tmax', overwrite = T)

# use Susans maps as a mask
cropped <- crop(res_us, sbeale)
mask_aligned <- resample(sbeale, cropped, method="near")
final <- mask(cropped, mask_aligned)
plot(final)

writeCDF(final, paste0(results_folder, "jan_fullregion_masked.nc"), varname='tmax', overwrite = T)
```
